{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import clone_model\n",
    "from datasets import get_data, get_training_data\n",
    "from models import get_model, resnet_v1, resnet_v2\n",
    "from util import select_clean_uncertain, combine_result, inject_noise\n",
    "import time\n",
    "import argparse\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "from keras import backend as K\n",
    "from io import BytesIO\n",
    "from loss_acc_plot import loss_acc_plot\n",
    "from keras.datasets import mnist, cifar10, cifar100, fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50000, 32, 32, 3)\n",
      "y_train: (50000, 10)\n",
      "X_test: (10000, 32, 32, 3)\n",
      "y_test (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = {'mnist': 10, 'svhn': 10, 'cifar-10': 10, 'cifar-100': 100, 'celeb': 20}\n",
    "dataset = \"cifar-10\"\n",
    "init_noise_ratio = 0\n",
    "data_ratio = 100.0\n",
    "X_train, y_train, X_test, y_test, un_selected_index = get_data(dataset, init_noise_ratio, data_ratio, random_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_client = 4\n",
    "client_data_number = [4000, 6000, 6000, 8000]\n",
    "clients = []\n",
    "clients_train_data = []\n",
    "clients_train_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = 0\n",
    "image_shape = X_train.shape[1:]\n",
    "server =  get_model(dataset, input_tensor=None, input_shape=image_shape, num_classes=NUM_CLASSES[dataset])\n",
    "# initialize n_client models, and the correspondante training data for each client\n",
    "# each client has different data size\n",
    "for i in range(n_client):\n",
    "    clients.append(get_model(dataset, input_tensor=None, input_shape=image_shape, num_classes=NUM_CLASSES[dataset]))\n",
    "    clients_train_data.append(X_train[cursor: cursor+client_data_number_interval*(i+1)])\n",
    "    clients_train_label.append(y_train[cursor: cursor+client_data_number_interval*(i+1)])\n",
    "    cursor = cursor + client_data_number_interval*(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(lr=0.01, decay=1e-4, momentum=0.9)\n",
    "server.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "for i in range(n_client):\n",
    "    clients[i].compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center = False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center = False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization = False,  # divide each input by its std\n",
    "        zca_whitening = False,  # apply ZCA whitening\n",
    "        rotation_range = 0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip = False,  # randomly flip images\n",
    "        )\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-c3c22c32727b>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 27s 870ms/step - loss: 6.9797 - accuracy: 0.2949 - val_loss: 6.9391 - val_accuracy: 0.2448\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 28s 900ms/step - loss: 6.0528 - accuracy: 0.4339 - val_loss: 5.9455 - val_accuracy: 0.3595\n",
      "Epoch 1/2\n",
      "62/62 [==============================] - 39s 625ms/step - loss: 6.5738 - accuracy: 0.3404 - val_loss: 5.9701 - val_accuracy: 0.3645\n",
      "Epoch 2/2\n",
      "62/62 [==============================] - 39s 625ms/step - loss: 5.1897 - accuracy: 0.4713 - val_loss: 5.0395 - val_accuracy: 0.3453\n",
      "Epoch 1/2\n",
      "93/93 [==============================] - 47s 508ms/step - loss: 6.2223 - accuracy: 0.3678 - val_loss: 5.3077 - val_accuracy: 0.4203\n",
      "Epoch 2/2\n",
      "93/93 [==============================] - 46s 499ms/step - loss: 4.5456 - accuracy: 0.4907 - val_loss: 4.3810 - val_accuracy: 0.3941\n",
      "Epoch 1/2\n",
      "125/125 [==============================] - 58s 461ms/step - loss: 5.9353 - accuracy: 0.3893 - val_loss: 5.2102 - val_accuracy: 0.3213\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - 57s 460ms/step - loss: 4.0235 - accuracy: 0.5116 - val_loss: 3.7678 - val_accuracy: 0.3969\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "results = []\n",
    "# 2 is only for quick test, need to set a large number\n",
    "epochs = 2\n",
    "for i in range(n_client):\n",
    "    results.append(\n",
    "        clients[i].fit_generator(datagen.flow(clients_train_data[i], clients_train_label[i], batch_size=batch_size),\n",
    "                                steps_per_epoch=clients_train_data[i].shape[0]//batch_size, epochs=epochs,\n",
    "                                validation_data=(X_test, y_test)\n",
    "                                )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weights(client_list):\n",
    "    n_client = len(client_list)\n",
    "    n_layers = len(client_list[0].get_weights())\n",
    "    if n_client == 0:\n",
    "        print('empty input')\n",
    "        return\n",
    "    # copy the weights and structure from last client\n",
    "    result = client_list[n_client-1].get_weights().copy()\n",
    "    for k in range(n_client):\n",
    "        result[k] = result[k]*(1.0/n_client)    \n",
    "    for i in range(n_layers):\n",
    "        # Using n_client -1: because result contains already last client's weights\n",
    "        for j in range(n_client-1):\n",
    "            result[i] = result[i] + client_list[j].get_weights()[i]*(1.0/n_client)            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = aggregate_weights(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data with all model aggregation\n",
      "157/157 [==============================] - 14s 86ms/step - loss: 8.1305 - accuracy: 0.1254\n",
      "test loss, test acc: [8.130518913269043, 0.12540000677108765]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data with all model aggregation\")\n",
    "results = server.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(\"test loss, test acc:\", results)\n",
    "# accuracy_aggregate is the baseline to calculate influence\n",
    "# influence is the difference between accurate_aggregatea and accuracy without one of client\n",
    "accuracy_aggregate = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove client:  0\n",
      "Evaluate on test data with chosen models\n",
      "157/157 [==============================] - 14s 89ms/step - loss: 6.2480 - accuracy: 0.1939\n",
      "test loss, test acc: [6.2480149269104, 0.193900004029274]\n",
      "remove client:  1\n",
      "Evaluate on test data with chosen models\n",
      "157/157 [==============================] - 14s 89ms/step - loss: 7.7863 - accuracy: 0.1419\n",
      "test loss, test acc: [7.786316394805908, 0.14190000295639038]\n",
      "remove client:  2\n",
      "Evaluate on test data with chosen models\n",
      "157/157 [==============================] - 14s 89ms/step - loss: 7.7453 - accuracy: 0.1554\n",
      "test loss, test acc: [7.74527645111084, 0.15539999306201935]\n",
      "remove client:  3\n",
      "Evaluate on test data with chosen models\n",
      "157/157 [==============================] - 14s 90ms/step - loss: 8.4093 - accuracy: 0.1134\n",
      "test loss, test acc: [8.409296989440918, 0.11339999735355377]\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_client):\n",
    "    chosen_number = list(np.arange(4))\n",
    "    chosen_number.remove(i)\n",
    "    print('remove client: ', i)\n",
    "    chosen_clients = [clients[index] for index in chosen_number]\n",
    "    sub_weights = aggregate_weights(chosen_clients)\n",
    "    server.set_weights(sub_weights)\n",
    "    print(\"Evaluate on test data with chosen models\")\n",
    "    results = server.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print(\"test loss, test acc:\", results)\n",
    "    influence.append(accuracy_aggregate - results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06849999725818634, -0.016499996185302734, -0.0299999862909317, 0.012000009417533875]\n"
     ]
    }
   ],
   "source": [
    "print(influence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
